{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af842f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KO H06\n",
    "#satunnaismetsä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eda3345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['targeted_productivity', 'smv', 'wip', 'over_time', 'incentive',\n",
      "       'idle_time', 'idle_men', 'no_of_style_change', 'no_of_workers',\n",
      "       'actual_productivity', 'class'],\n",
      "      dtype='object')\n",
      "First row by position: targeted_productivity       0.800000\n",
      "smv                        26.160000\n",
      "wip                      1108.000000\n",
      "over_time                7080.000000\n",
      "incentive                  98.000000\n",
      "idle_time                   0.000000\n",
      "idle_men                    0.000000\n",
      "no_of_style_change          0.000000\n",
      "no_of_workers              59.000000\n",
      "actual_productivity         0.940725\n",
      "class                       1.000000\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "\n",
    "#luetaan data\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00597/garments_worker_productivity.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#tipautetaan oletettavasti merkityksettömät taustamuuttujat\n",
    "df.drop(columns=['date','day','quarter','department','team'], inplace=True)\n",
    "\n",
    "#tehdään luokkamuuttujaa varten pieni funktio\n",
    "def productivity_to_class(df):\n",
    "    if df['actual_productivity'] >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#ja luodaan luokkamuuttuja \n",
    "df['class'] = df.apply(lambda x: productivity_to_class(x), axis=1)\n",
    "\n",
    "#täytetään NaNit sarakkeen keskiarvolla\n",
    "fill_value = df['wip'].mean()\n",
    "df['wip'].fillna(fill_value, inplace=True)\n",
    "\n",
    "#eriytetään luokka ja tuottavuus\n",
    "#indeksit tulevan tarpeen mukaisessa järjestyksessä\n",
    "y1 = df['actual_productivity']\n",
    "y2 = df['class']\n",
    "X = df.drop(columns=['actual_productivity','class'])\n",
    "\n",
    "print(f'Columns: {df.columns}')\n",
    "print(f'First row by position: {df.iloc[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b26ca",
   "metadata": {},
   "source": [
    "# oma kommentti\n",
    "Olettaisin, ettei sarakkeilla `'day'`,`'date'`,`'quarter'`,`'department'` ja `'team'` ole analyysissä hirveän suurta painoarvoa ja droppasin ne. (Viikonpäivän tosin voisi ajatella vaikuttavan, ainakin jos viikonloppu lähestyy. Datan taustatiedoista jää kuitenkin epäselväksi milloin viikonloppu on, ja onko tutkituilla edes vapaata silloin.)\n",
    "\n",
    "Work in progress (`wip`) -sarakkeessa oli puuttuvia arvoja. Koska niiden määrä on tyypillisesti melko suuri, korvasin puuttuvat arvot sarakkeen keskiarvolla, jolloin ne eivät (likimain normaalijakauma olettaen) heiluta sarakkeen painoa.\n",
    "\n",
    "Algoritmia varten tehtiin juoksevasta `actual_productivity` -arvosta luokkamuuttuja `class`, jonka arvo on yksi, jos työläinen oli keskimääräistä tuottavampi ja nolla muutoin. Taaskaan ei normalisoida ennen datan jakamista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c74ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length: 396\n",
      "Train length: 801\n",
      "Train columns: RangeIndex(start=0, stop=9, step=1)\n",
      "Explained variance: 0.3686123761563034\n",
      "Maximum error: 0.587630922640574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score, max_error\n",
    "\n",
    "#jaetaan data. tehdään tässä kerralla molemmat y:t\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(X, y1, y2, test_size=0.33, random_state=23)\n",
    "\n",
    "#ja nyt normalisoidaan\n",
    "sts = StandardScaler()\n",
    "X_train = pd.DataFrame(sts.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(sts.transform(X_test))\n",
    "\n",
    "#koulutetaan satunnaismetsä\n",
    "rfr = RandomForestRegressor(random_state=753) #n_estimators=100, max_depth=???\n",
    "rfr.fit(X_train, y1_train)\n",
    "\n",
    "#ennuste\n",
    "y1_pred = rfr.predict(X_test)\n",
    "\n",
    "#selittyvä varianssi sekä maksimivirhe\n",
    "exp_var = explained_variance_score(y1_test, y1_pred)\n",
    "max_err = max_error(y1_test, y1_pred)\n",
    "\n",
    "print(f'Test length: {len(X_test)}')\n",
    "print(f'Train length: {len(X_train)}')\n",
    "print(f'Train columns: {X_train.columns}')\n",
    "print(f'Explained variance: {exp_var}')\n",
    "print(f'Maximum error: {max_err}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ad6ab",
   "metadata": {},
   "source": [
    "# oma kommentti\n",
    "Tässä tehtiin kerralla kaikki tehtäväpaketissa tarvittavat `y`-aineistot ja sen jälkeen normalisoitiin `X`-aineistot. Vaikka päätöspuu ei olekaan herkkä datan arvojen erisuuruuksille, tässä tehtävässä regressiossa normalisointi voi olla fiksua, koska suureiden skaalaaminen samalle asteikolle joka tapauksessa parantaa mallin yleistämiskykyä. Skaalausta ei tehty  `actual_productivity`:lle. Vaikka se onkin jatkuva suure, on vaikea keksiä, mitä sillä saavutettaisiin. \n",
    "\n",
    "Päätöspuiden lukumäärää tai maksimisyvyyttä ei ole annettu, joten mennään oletusarvoilla, jolloin puita on 100 ja niitä kasvatetaan kunnes ne saavuttavat luonnollisen maksimin. Lopputulosta tarkastellaan `metrics`-moduulin funktioilla. Päätösuu on konseptina tuttu, mutta regressioanalyysin tekeminen niiden avulla on ajatuksena hieman vieras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f0afd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length: 396\n",
      "Train length: 801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.43      0.43        35\n",
      "           1       0.94      0.95      0.95       361\n",
      "\n",
      "    accuracy                           0.90       396\n",
      "   macro avg       0.69      0.69      0.69       396\n",
      "weighted avg       0.90      0.90      0.90       396\n",
      "\n",
      "[[ 15  20]\n",
      " [ 19 342]]\n",
      "feature: targeted_productivity - relative importance: 22.3 %\n",
      "feature:          smv - relative importance: 18.9 %\n",
      "feature:          wip - relative importance: 12.1 %\n",
      "feature:    over_time - relative importance: 17.7 %\n",
      "feature:    incentive - relative importance: 11.0 %\n",
      "feature:    idle_time - relative importance:  1.5 %\n",
      "feature:     idle_men - relative importance:  2.2 %\n",
      "feature: no_of_style_change - relative importance:  1.5 %\n",
      "feature: no_of_workers - relative importance: 12.9 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#koulutetaan luokittelija\n",
    "rfc = RandomForestClassifier(random_state=753)\n",
    "rfc.fit(X_train, y2_train)\n",
    "\n",
    "#ennustetaan\n",
    "y2_pred = rfc.predict(X_test)\n",
    "\n",
    "#tarkastellaan onnistumista\n",
    "cr = classification_report(y2_test, y2_pred)\n",
    "cm = confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "print(f'Test length: {len(X_test)}')\n",
    "print(f'Train length: {len(X_train)}')\n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "#katsotaan vielä mikä oikeastaan vaikutti luokitteluun\n",
    "importances = rfc.feature_importances_\n",
    "for i in range(len(importances)):\n",
    "    print(\"feature: %12s - relative importance: %4.1f %%\" % (X.columns[i], importances[i] * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce023c",
   "metadata": {},
   "source": [
    "# oma kommentti\n",
    "Viimeisessä tehtävässä satunnaismetsä-luokittelijan piti ennustaa `class`-luokkamuuttuja ja sehän onnistui kohtalaisen hyvin. Luentomateriaaleista löytyi kiva suhteellisen merkittävyyden työkalu, joka kertoo tehokkuuteen vaikuttavan erityisesti asetettu tuottavuustavoite (`targeted_productivity`) sekä työhön varattu aika ja sen ylitys (`smv` ja `over_time`). Taloudellinen kannuste (`incentive`) jää omasta mielestäni yllättävän matalalle painolle. Tekemistä varmaankin siis riittää. Tulokset vaikuttavat kokonaisuutena ihan mielekkäiltä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5bc8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
